{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to PyMC\n",
    "\n",
    "This notebook is to accompany the IAA intro to Bayes and PyMC deck. \n",
    "\n",
    "This notebook will walk through a few simple examples:\n",
    "0. Getting data and packages\n",
    "1. A naive PyMC model - basic framework\n",
    "2. A simple regression model with one predictor\n",
    "3. A regression model with multiple predictors\n",
    "\n",
    "I ain't no expert. But the PyMC community is _full_ of experts. So we'll close with how to leverage them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing data\n",
    "test_scores = pd.read_csv(pm.get_data(\"test_scores.csv\"), index_col=0)\n",
    "test_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping missing values is a very bad idea in general, but we do so here for simplicity\n",
    "X = test_scores.dropna().astype(float)\n",
    "y = X.pop(\"score\")\n",
    "\n",
    "# Because we often need to reference the dimensions later on\n",
    "N, D = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example\n",
    "Model of the standardized test score, y. \n",
    "\n",
    "For this version, we're just focused on the PyMC framework. We have no predictors, just a naive model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = pm.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    # Priors for unknown model parameters\n",
    "    mu = pm.Normal('mu', mu=100, sigma=20)\n",
    "    sigma = pm.Uniform('sigma', lower=0, upper=50)\n",
    "\n",
    "    # Data generating process\n",
    "    score = pm.Normal('score', mu=mu, sigma=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the model specification, we're specifying our priors, as we have to give that directly. Then we give the data generating process, where the ```score``` is generated from a Normal distribution, centered at ```mu``` with noise defined by ```sigma```. We're not computing the likelihood here, just declaring the generative story for how the data arose - our _model_. \n",
    "\n",
    "2. Arviz is a powerful package to help visualize and summarize your probabilistic models. This model is pretty unintersting, but it should give you an idea of what this visual representation of the model can do, and how to interpret it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    # Draw samples from the prior predictive distribution\n",
    "    prior_pred = pm.sample_prior_predictive(samples=500)\n",
    "\n",
    "# Use ArviZ to visualize the distribution of `score`\n",
    "az.plot_dist(prior_pred.prior_predictive['score'], \n",
    "             label='Prior Predictive Distribution of Score',\n",
    "             color='skyblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(basic_model)\n",
    "\n",
    "# super helpful to sanity check our model structure\n",
    "# https://graphviz.readthedocs.io/en/stable/manual.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    # draw posterior samples, all defaults\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, combined=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Regression with One Predictor\n",
    "\n",
    "Here we're adding a predictor variable. So we want to formulate our model mathematically, then we can specify that model in PyMC and sample to our heart's content. \n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\text{score}_i &\\sim \\mathcal{N}(\\mu_i,\\ \\sigma) \\\\\n",
    "\\alpha &\\sim \\mathcal{N}(100,\\ 50) \\\\\n",
    "\\beta &\\sim \\mathcal{N}(0,\\ 10) \\\\\n",
    "\\sigma &\\sim \\text{HalfNormal}(25) \\\\\n",
    "\\mu_i &= \\alpha + \\beta \\cdot \\text{sibling}_i \\\\\n",
    "\\end{aligned}\n",
    "\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['siblings'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pm.Model() as simple_model:\n",
    "    #Priors\n",
    "    alpha = pm.Normal('alpha', mu=100, sigma=50)\n",
    "    beta = pm.Normal('beta', mu=0, sigma=10)\n",
    "    sigma = pm.HalfNormal('sigma', sigma=25)\n",
    "\n",
    "    # Linear model\n",
    "    mu = alpha + beta * X['siblings'].values\n",
    "\n",
    "    # Data generating process\n",
    "    score = pm.Normal('score', mu=mu, sigma=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with simple_model:\n",
    "    idata_simple = pm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression Model\n",
    "\n",
    "\n",
    "We model the test score as a linear combination of multiple predictors. The model is:\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\text{score}_i &\\sim \\mathcal{N}(\\mu_i,\\ \\sigma) \\\\\n",
    "\\alpha &\\sim \\mathcal{N}(100,\\ 50) \\\\\n",
    "\\beta_j &\\sim \\mathcal{N}(0,\\ 10) \\quad \\text{for each predictor } j \\\\\n",
    "\\sigma &\\sim \\text{HalfNormal}(25) \\\\\n",
    "\\mu_i &= \\alpha + \\sum_{j=1}^D \\beta_j \\cdot x_{ij} \\\\\n",
    "\\end{aligned}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"predictors\": X.columns.values}\n",
    "\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "with pm.Model(coords = coords) as multi_model:\n",
    "\n",
    "    # Priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=100, sigma=50) # intercept\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=10, dims=\"predictors\") # regression coefficients\n",
    "    sigma = pm.Uniform(\"sigma\", lower=0, upper=20) # error SD\n",
    "    \n",
    "    # linear model\n",
    "    # show the one I fucked up first:\n",
    "    #score = pm.Normal(\"score\", sigma + pt.dot(X.values, beta), sigma, observed=y.values)\n",
    "    score = pm.Normal(\"score\", alpha + pt.dot(X.values, beta), sigma, observed=y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(multi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multi_model:\n",
    "    idata_multi = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(idata_multi, var_names=[\"beta\"], combined=True, hdi_prob=0.95, r_hat=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add intercept manually since statsmodels does not do it by default methinks\n",
    "X_ols = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "ols_model = sm.OLS(y, X_ols).fit()\n",
    "print(ols_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "1. Go here for more: https://www.pymc.io/welcome.html\n",
    "    * Examples, tips, links, further reading\n",
    "2. Be part of the Discourse here: https://discourse.pymc.io/\n",
    "3. Read \"Statistical Rethinking\"\n",
    "4. Listen to \"Learning Bayesian Statistics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictable_jokes import tell_joke\n",
    "\n",
    "tell_joke(topic=\"Bayes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
